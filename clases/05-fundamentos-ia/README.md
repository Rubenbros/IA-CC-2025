# Clase 05: Fundamentos de Inteligencia Artificial y Machine Learning

## Descripci√≥n General

Esta clase cubre los conceptos fundamentales de Inteligencia Artificial y Machine Learning desde una perspectiva te√≥rica y pr√°ctica, con ejemplos aplicables a diversos dominios.

## Contenido del Curso

### üìö Documentaci√≥n Te√≥rica

#### 1. [Teor√≠a de Fundamentos de IA y ML](teoria_fundamentos_ia_ml.md)

Documento principal con teor√≠a completa y generalizada:

**Contenido:**
- **Parte 1**: Introducci√≥n a la Inteligencia Artificial
  - ¬øQu√© es IA? Niveles de IA (D√©bil, Fuerte, Super)
  - Diferencia entre programaci√≥n tradicional y ML

- **Parte 2**: Fundamentos Matem√°ticos
  - Probabilidad b√°sica y condicional
  - Teorema de Bayes con ejemplos aplicados
  - Distribuciones de probabilidad (uniforme, normal, binomial)
  - Valor esperado
  - Entrop√≠a de Shannon y teor√≠a de la informaci√≥n

- **Parte 3**: Tipos de Aprendizaje Autom√°tico
  - Aprendizaje Supervisado (regresi√≥n y clasificaci√≥n)
  - Aprendizaje No Supervisado (clustering, reducci√≥n dimensional)
  - Aprendizaje por Refuerzo (Q-Learning, pol√≠ticas)
  - Comparaci√≥n y cu√°ndo usar cada tipo

- **Parte 4**: Algoritmos Fundamentales
  - Regresi√≥n Lineal
  - Cadenas de Markov
  - N-gramas y modelos de lenguaje
  - K-Nearest Neighbors (KNN)
  - Ensemble Methods (Bagging, Boosting, Stacking)

- **Parte 5**: M√©tricas y Evaluaci√≥n
  - M√©tricas de clasificaci√≥n (Accuracy, Precision, Recall, F1)
  - Matriz de confusi√≥n
  - M√©tricas de regresi√≥n (MSE, RMSE, R¬≤, MAE)
  - Train/Validation/Test split
  - K-Fold Cross-Validation
  - Overfitting vs Underfitting

- **Parte 6**: Conceptos Avanzados
  - Teor√≠a de la informaci√≥n
  - Batch vs Online Learning
  - Pipeline de ML
  - Feature Engineering

#### 2. [Ejemplos y Aplicaciones Pr√°cticas](ejemplos_aplicaciones_ia.md)

Documento con casos de uso reales y aplicaciones en diversos dominios:

**Contenido:**
- **Procesamiento de Lenguaje Natural (NLP)**
  - An√°lisis de sentimientos
  - Chatbots y asistentes virtuales
  - Clasificaci√≥n de intenciones

- **Visi√≥n por Computadora**
  - Clasificaci√≥n de im√°genes (MNIST, ImageNet)
  - Detecci√≥n de objetos (YOLO, R-CNN)
  - Segmentaci√≥n sem√°ntica (U-Net)

- **Sistemas de Recomendaci√≥n**
  - Filtrado colaborativo (user-based, item-based)
  - Filtrado basado en contenido
  - Sistemas h√≠bridos (Netflix)

- **Detecci√≥n de Fraude**
  - Fraude en transacciones bancarias
  - Detecci√≥n de bots y spam
  - An√°lisis de anomal√≠as

- **Predicci√≥n de Series Temporales**
  - Predicci√≥n de demanda (ARIMA, Prophet)
  - Forecasting de ventas
  - Predicci√≥n de precios

- **Diagn√≥stico M√©dico Asistido**
  - Detecci√≥n de c√°ncer en im√°genes
  - Predicci√≥n de readmisi√≥n hospitalaria
  - Transfer learning en medicina

#### 3. [Feature Engineering: Teor√≠a y Pr√°ctica](feature_engineering_teoria.md) ‚≠ê NUEVO

Documento completo sobre ingenier√≠a de caracter√≠sticas aplicada al proyecto PPT:

**Contenido:**
- **Fundamentos Te√≥ricos**
  - ¬øQu√© es Feature Engineering y por qu√© es cr√≠tico?
  - El problema de representaci√≥n y espacio de features
  - Informaci√≥n mutua y maldici√≥n de la dimensionalidad
  - Principio de parsimonia (Navaja de Occam)

- **Tipos de Features**
  - Features b√°sicas (directas)
  - Features derivadas (transformaciones)
  - Features de agregaci√≥n (estad√≠sticos)
  - Features temporales (ventanas, lags)
  - Features de codificaci√≥n (Label, One-Hot)
  - Features de interacci√≥n (combinaciones)
  - Features de dominio (conocimiento experto)

- **T√©cnicas Avanzadas**
  - Extracci√≥n de componentes
  - Binning (discretizaci√≥n)
  - Transformaciones matem√°ticas (log, sqrt, normalizaci√≥n)
  - Ventanas deslizantes (sliding windows)
  - Lag features (retardos)
  - Features de frecuencia
  - Features de entrop√≠a (aleatoriedad)

- **Aplicaci√≥n Espec√≠fica a Piedra, Papel o Tijera**
  - 8 categor√≠as de features para el proyecto
  - Ejemplo completo: de datos crudos a vector de features
  - C√≥digo de implementaci√≥n en Python
  - Visualizaciones y an√°lisis

- **Validaci√≥n y Selecci√≥n**
  - An√°lisis de correlaci√≥n
  - Informaci√≥n mutua
  - Feature importance
  - Eliminaci√≥n de features redundantes
  - Validaci√≥n temporal (cr√≠tica para secuencias)

- **Mejores Pr√°cticas**
  - Evitar data leakage
  - Escalado de features
  - Manejo de valores faltantes
  - Feature engineering iterativo
  - Documentaci√≥n

- **Ejercicios Propuestos**
  - 6 ejercicios pr√°cticos con soluciones

### üíª Notebooks Pr√°cticos

#### 1. [Ejemplos ML Generales](../../src/clase05_fundamentos_ia/ejemplos_ml_generales.ipynb)

Notebook interactivo con c√≥digo ejecutable:

**Contenido:**
- **Regresi√≥n Lineal**: Predicci√≥n de precios de casas
  - Feature engineering
  - Interpretaci√≥n de coeficientes
  - M√©tricas (R¬≤, RMSE)
  - Visualizaci√≥n de predicciones

- **Clasificaci√≥n**: Detecci√≥n de spam en emails
  - Vectorizaci√≥n de texto (TF-IDF)
  - Naive Bayes classifier
  - Matriz de confusi√≥n
  - Precision vs Recall

- **Clustering**: Segmentaci√≥n de clientes
  - K-Means clustering
  - M√©todo del codo para elegir K
  - Normalizaci√≥n de datos
  - Interpretaci√≥n de clusters

#### 2. [Teor√≠a Completa con C√≥digo](../../src/clase05_fundamentos_ia/teoria_completa_con_codigo.ipynb)

Notebook original con ejemplos aplicados (incluye caso de estudio de juegos estrat√©gicos).

#### 3. [Feature Engineering PPT](../../src/clase05_fundamentos_ia/feature_engineering_ppt.py) ‚≠ê NUEVO

Script Python con implementaci√≥n completa de feature engineering para el proyecto Piedra, Papel o Tijera:

**Contenido:**
- **Clase PPTFeatureEngineering**: Implementaci√≥n completa y reutilizable
- **Features de Frecuencia**: Globales y en ventanas temporales
- **Features de Patrones**: Lags, bigramas, trigramas, detecci√≥n de cambios
- **Features de Rachas**: Victorias/derrotas consecutivas, r√©cords
- **Features Temporales**: Tiempo de reacci√≥n, fases del juego, aceleraci√≥n
- **Features de Entrop√≠a**: Medici√≥n de aleatoriedad y predictibilidad
- **Features de Markov**: Matrices de transici√≥n, predicciones probabil√≠sticas
- **Features de Respuesta**: C√≥mo reacciona el oponente a victorias/derrotas
- **Ejemplos de Uso**: 3 ejemplos completos con visualizaciones
- **C√≥digo Documentado**: Listo para usar en el proyecto

**C√≥mo ejecutar:**
```bash
python src/clase05_fundamentos_ia/feature_engineering_ppt.py
```

#### 4. [Ejemplo de Uso con CSV](../../src/clase05_fundamentos_ia/ejemplo_uso_csv.py) ‚≠ê NUEVO

Script completo que muestra el workflow desde CSV hasta dataset listo para ML:

**Contenido:**
- **Cargar CSV b√°sico**: Solo 3 columnas (numero_ronda, jugada_jugador, jugada_oponente)
- **Generar features para cada ronda**: Procesamiento completo del historial
- **Crear DataFrame final**: M√°s de 30 features generadas autom√°ticamente
- **Preparar para ML**: Separaci√≥n de features (X) y objetivo (y)
- **Ejemplo incremental**: C√≥mo usar en tiempo real durante el juego
- **C√≥digo comentado**: Cada paso explicado claramente

**C√≥mo ejecutar:**
```bash
python src/clase05_fundamentos_ia/ejemplo_uso_csv.py
```

**Resultado:** Genera dos archivos CSV:
- `dataset_ppt_ejemplo.csv` - Datos originales (3 columnas)
- `dataset_ppt_con_features.csv` - Dataset completo para entrenar modelos (30+ columnas)

## C√≥mo Usar Este Material

### Para Estudiantes

**Ruta de Aprendizaje Sugerida:**

1. **Empezar con teor√≠a b√°sica** (1-2 horas):
   - Leer Parte 1 y 2 de `teoria_fundamentos_ia_ml.md`
   - Entender conceptos de probabilidad y entrop√≠a

2. **Tipos de aprendizaje** (1 hora):
   - Leer Parte 3 de `teoria_fundamentos_ia_ml.md`
   - Entender cu√°ndo usar cada tipo

3. **Pr√°ctica con ejemplos** (2-3 horas):
   - Ejecutar `ejemplos_ml_generales.ipynb`
   - Experimentar cambiando par√°metros
   - Probar con datos propios

4. **Algoritmos espec√≠ficos** (2 horas):
   - Leer Parte 4 de `teoria_fundamentos_ia_ml.md`
   - Implementar versiones simples de algoritmos

5. **M√©tricas y evaluaci√≥n** (1 hora):
   - Leer Parte 5
   - Practicar interpretaci√≥n de matrices de confusi√≥n

6. **Feature Engineering** (3-4 horas) ‚≠ê NUEVO:
   - Leer `feature_engineering_teoria.md` completo
   - Ejecutar `feature_engineering_ppt.py`
   - Hacer los ejercicios propuestos
   - Aplicar al proyecto PPT

7. **Aplicaciones reales** (1-2 horas):
   - Leer `ejemplos_aplicaciones_ia.md`
   - Elegir un dominio de inter√©s
   - Investigar m√°s sobre ese dominio

### Para Docentes

**Material did√°ctico incluido:**

- **Diapositivas potenciales**: Usar secciones de `teoria_fundamentos_ia_ml.md`
- **Ejercicios pr√°cticos**: Adaptar notebooks para laboratorios
- **Evaluaciones**: Usar conceptos te√≥ricos y ejercicios pr√°cticos
- **Proyectos**: Inspirarse en `ejemplos_aplicaciones_ia.md`

**Estructura de clase sugerida:**

- **Sesi√≥n 1** (2h): Introducci√≥n a IA, probabilidad b√°sica
- **Sesi√≥n 2** (2h): Tipos de aprendizaje, algoritmos b√°sicos
- **Sesi√≥n 3** (2h): Pr√°ctica con regresi√≥n y clasificaci√≥n
- **Sesi√≥n 4** (2h): Clustering y m√©tricas avanzadas
- **Sesi√≥n 5** (2h): Aplicaciones reales y proyecto final

## Recursos Adicionales

### Libros Recomendados

**Nivel Principiante:**
- "The Hundred-Page Machine Learning Book" - Andriy Burkov
- "Machine Learning for Absolute Beginners" - Oliver Theobald

**Nivel Intermedio:**
- "Hands-On Machine Learning" - Aur√©lien G√©ron
- "Python Machine Learning" - Sebastian Raschka

**Nivel Avanzado:**
- "Pattern Recognition and Machine Learning" - Christopher Bishop
- "The Elements of Statistical Learning" - Hastie, Tibshirani, Friedman

### Cursos Online

- **Andrew Ng - Machine Learning** (Coursera)
- **Fast.ai - Practical Deep Learning**
- **Google Machine Learning Crash Course**
- **MIT 6.034 Artificial Intelligence** (YouTube)

### Datasets para Practicar

- **Kaggle**: Miles de datasets y competiciones
- **UCI ML Repository**: Datasets cl√°sicos educativos
- **Scikit-learn**: Datasets integrados para pr√°ctica r√°pida
- **TensorFlow Datasets**: Colecci√≥n amplia para deep learning

### Herramientas y Librer√≠as

**Python Essentials:**
```python
# Datos y computaci√≥n
import pandas as pd
import numpy as np

# Machine Learning
from sklearn import *
import xgboost as xgb
import lightgbm as lgb

# Visualizaci√≥n
import matplotlib.pyplot as plt
import seaborn as sns

# Deep Learning
import tensorflow as tf
import torch
```

## Proyectos Sugeridos

### Nivel B√°sico (5-6 puntos)

1. **Predictor de precios**: Regresi√≥n lineal para precios de casas/coches
2. **Clasificador de flores**: Iris dataset con m√∫ltiples algoritmos
3. **An√°lisis exploratorio**: Dataset de tu elecci√≥n con visualizaciones

### Nivel Intermedio (7-8 puntos)

4. **Sistema de recomendaci√≥n**: Pel√≠culas, m√∫sica o productos
5. **Detector de spam**: Con features personalizadas
6. **Segmentaci√≥n de clientes**: K-Means + an√°lisis de negocios
7. **Predicci√≥n de churn**: Clasificaci√≥n con datos desbalanceados

### Nivel Avanzado (9-10 puntos)

8. **An√°lisis de sentimientos**: NLP con redes neuronales
9. **Clasificador de im√°genes**: CNN con transfer learning
10. **Sistema de detecci√≥n de fraude**: Anomaly detection + ensemble
11. **Chatbot simple**: Intent classification + response generation
12. **Predicci√≥n de series temporales**: ARIMA o LSTM

## Evaluaci√≥n

### Criterios de Evaluaci√≥n

**Conocimientos Te√≥ricos (40%):**
- Comprensi√≥n de conceptos fundamentales
- Capacidad de explicar algoritmos
- Entendimiento de m√©tricas

**Implementaci√≥n Pr√°ctica (40%):**
- C√≥digo funcional y bien estructurado
- Uso apropiado de librer√≠as
- Validaci√≥n correcta de modelos

**An√°lisis y Comunicaci√≥n (20%):**
- Interpretaci√≥n de resultados
- Visualizaciones claras
- Documentaci√≥n del proceso

### R√∫brica de Proyecto

| Aspecto | B√°sico (5-6) | Intermedio (7-8) | Avanzado (9-10) |
|---------|--------------|------------------|-----------------|
| **Complejidad** | Algoritmo simple, datos limpios | M√∫ltiples algoritmos, preprocesamiento | Ensemble, feature engineering avanzado |
| **M√©tricas** | Accuracy b√°sico | M√∫ltiples m√©tricas, validaci√≥n cruzada | An√°lisis profundo, intervalos confianza |
| **C√≥digo** | Funcional, b√°sico | Modular, comentado | Producci√≥n-ready, tests |
| **An√°lisis** | Descripci√≥n b√°sica | Interpretaci√≥n detallada | Insights accionables, recomendaciones |

## Preguntas Frecuentes

**P: ¬øNecesito conocimientos avanzados de matem√°ticas?**
R: No necesariamente. Los conceptos b√°sicos de probabilidad y √°lgebra lineal son suficientes para empezar.

**P: ¬øQu√© lenguaje de programaci√≥n es mejor?**
R: Python es el est√°ndar de facto en ML. R tambi√©n es popular en estad√≠stica.

**P: ¬øCu√°nto tiempo toma aprender ML?**
R: Conceptos b√°sicos: 2-3 meses. Nivel intermedio: 6-12 meses. Maestr√≠a: a√±os de pr√°ctica.

**P: ¬øNecesito GPU para entrenar modelos?**
R: Para empezar, no. CPU es suficiente. Para deep learning, GPU acelera significativamente.

**P: ¬øC√≥mo encuentro mi primer trabajo en ML?**
R: Portfolio en GitHub, proyectos en Kaggle, contribuciones open source, networking.

## Contribuciones

Este material es educativo y est√° en constante evoluci√≥n. Sugerencias y mejoras son bienvenidas.

## Licencia

Material educativo para uso acad√©mico.

---

**√öltima actualizaci√≥n**: Octubre 2024

**Autor**: Curso IA-CC-2025

**Contacto**: [Detalles del instructor]
