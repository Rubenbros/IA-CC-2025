# Fundamentos de Inteligencia Artificial y Machine Learning
## Conceptos Te√≥ricos y Matem√°ticos Fundamentales

---

# PARTE 1: INTRODUCCI√ìN A LA INTELIGENCIA ARTIFICIAL

## 1.1 ¬øQu√© es la Inteligencia Artificial?

La **Inteligencia Artificial (IA)** es la simulaci√≥n de procesos de inteligencia humana por parte de m√°quinas, especialmente sistemas inform√°ticos.

### Niveles de IA:
1. **IA D√©bil (Narrow AI)**: Dise√±ada para tareas espec√≠ficas
   - Ejemplo: Detectar spam, reconocer caras, recomendar productos, diagn√≥stico m√©dico asistido
   - Es el tipo de IA que usamos actualmente en aplicaciones reales
   - Excelente en su dominio espec√≠fico, pero no generalizable

2. **IA Fuerte (General AI)**: Capacidad humana generalizada
   - Todav√≠a no existe (investigaci√≥n en progreso)
   - Podr√≠a aprender y razonar en cualquier dominio como un humano

3. **Super IA**: Supera la inteligencia humana en todos los aspectos
   - Te√≥rica/futura
   - Implicaciones √©ticas y filos√≥ficas significativas

### Componentes clave de un sistema de IA:
```
ENTRADA (Datos) ‚Üí PROCESAMIENTO (Algoritmo) ‚Üí SALIDA (Predicci√≥n/Decisi√≥n)
     ‚Üë                                              ‚Üì
     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ RETROALIMENTACI√ìN (Aprendizaje) ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## 1.2 ¬øQu√© es Machine Learning?

**Machine Learning (ML)** es un subconjunto de la IA que permite a los sistemas aprender y mejorar autom√°ticamente a partir de la experiencia **sin ser programados expl√≠citamente**.

### Diferencia clave:
- **Programaci√≥n tradicional**: 
  ```
  Reglas + Datos ‚Üí Respuesta
  ```
- **Machine Learning**: 
  ```
  Datos + Respuestas ‚Üí Reglas (Modelo)
  ```

### Ejemplos pr√°cticos:
- **Tradicional**: "Si temperatura > 30¬∞C, entonces activar aire acondicionado"
- **ML**: "Bas√°ndome en temperatura, humedad, hora del d√≠a y preferencias hist√≥ricas, predecir configuraci√≥n √≥ptima del climatizador"

**Otro ejemplo:**
- **Tradicional**: "Si email contiene palabra 'viagra', entonces es spam"
- **ML**: "Bas√°ndome en millones de emails etiquetados, aprender patrones complejos que identifican spam"

---

# PARTE 2: FUNDAMENTOS MATEM√ÅTICOS

## 2.1 Probabilidad B√°sica

### Conceptos esenciales:

**Probabilidad**: Medida de la posibilidad de que ocurra un evento
- Rango: [0, 1] donde 0 = imposible, 1 = seguro
- P(A) = Casos favorables / Casos totales

**Ejemplos en Machine Learning:**
- **Clasificaci√≥n de im√°genes**: P(gato|imagen) = probabilidad de que la imagen contenga un gato
- **Detecci√≥n de fraude**: P(fraude|transacci√≥n) = probabilidad de que una transacci√≥n sea fraudulenta
- **Predicci√≥n del clima**: P(lluvia|condiciones_actuales) = probabilidad de lluvia dadas las condiciones
- **Diagn√≥stico m√©dico**: P(enfermedad|s√≠ntomas) = probabilidad de enfermedad dados los s√≠ntomas observados

### Regla de la Suma:
Para eventos mutuamente excluyentes:
```
P(A o B) = P(A) + P(B)

Ejemplo: Lanzar un dado
P(sacar 1 o 6) = P(1) + P(6) = 1/6 + 1/6 = 2/6 = 1/3

Aplicaci√≥n ML: Clasificaci√≥n multiclase
P(clase_A o clase_B) = P(clase_A) + P(clase_B)
```

### Regla del Producto:
Para eventos independientes:
```
P(A y B) = P(A) √ó P(B)

Ejemplo: Lanzar dos monedas
P(cara en moneda 1 Y cara en moneda 2) = 1/2 √ó 1/2 = 1/4

Aplicaci√≥n ML: Features independientes
P(email_spam Y contiene_enlace) = P(email_spam) √ó P(contiene_enlace)
(solo si son independientes)
```

## 2.2 Probabilidad Condicional

**Definici√≥n**: Probabilidad de A dado que B ya ocurri√≥
```
P(A|B) = P(A ‚à© B) / P(B)
```

**Ejemplos en Machine Learning:**
- **Filtro de spam**: P(spam | contiene_"oferta") = Probabilidad de que sea spam dado que contiene "oferta"
- **Reconocimiento facial**: P(persona_X | detecta_rostro) = Probabilidad de que sea la persona X dado que se detect√≥ un rostro
- **Predicci√≥n de compra**: P(compra | visit√≥_3_veces) = Probabilidad de compra dado que visit√≥ el sitio 3 veces
- **Diagn√≥stico**: P(diabetes | glucosa_alta) = Probabilidad de diabetes dado nivel alto de glucosa

### Teorema de Bayes:
```
P(A|B) = [P(B|A) √ó P(A)] / P(B)

Donde:
- P(A|B) = Probabilidad posterior (lo que queremos saber)
- P(B|A) = Verosimilitud (likelihood)
- P(A) = Probabilidad a priori
- P(B) = Evidencia (marginal)
```

**Aplicaci√≥n pr√°ctica - Detecci√≥n de spam:**
Queremos calcular: P(spam | contiene_"gratis")

Datos conocidos:
- P(contiene_"gratis" | spam) = 0.8 (80% de spams contienen "gratis")
- P(spam) = 0.3 (30% de emails son spam a priori)
- P(contiene_"gratis") = 0.4 (40% de todos los emails contienen "gratis")

Aplicando Bayes:
P(spam | contiene_"gratis") = [0.8 √ó 0.3] / 0.4 = 0.6 = 60%

**Otro ejemplo - Diagn√≥stico m√©dico:**
P(enfermedad | test_positivo) = [P(test_positivo | enfermedad) √ó P(enfermedad)] / P(test_positivo)

Esto es fundamental en clasificadores Naive Bayes.

## 2.3 Distribuciones de Probabilidad

### Distribuci√≥n Uniforme:
Todos los resultados tienen igual probabilidad
- **Ejemplo**: Lanzar un dado justo: P(1) = P(2) = ... = P(6) = 1/6
- **En ML**: Inicializaci√≥n de pesos en redes neuronales
- Entrop√≠a m√°xima (m√°xima incertidumbre)
- Sin sesgo hacia ninguna opci√≥n

### Distribuci√≥n Normal (Gaussiana):
La distribuci√≥n m√°s com√∫n en naturaleza y datos
```
Œº = media, œÉ = desviaci√≥n est√°ndar
f(x) = (1/(œÉ‚àö2œÄ)) √ó e^(-(x-Œº)¬≤/2œÉ¬≤)
```
- **Ejemplo**: Altura de personas, errores de medici√≥n, muchas features en datasets
- **En ML**: Asumida en muchos algoritmos (regresi√≥n lineal, LDA)
- Propiedad: 68% de datos dentro de ¬±1œÉ, 95% dentro de ¬±2œÉ

### Distribuci√≥n Binomial:
Probabilidad de k √©xitos en n intentos
- **Ejemplo**: N√∫mero de caras en 10 lanzamientos de moneda
- **En ML**: Clasificaci√≥n binaria, A/B testing

### Distribuci√≥n Sesgada (Skewed):
Algunas opciones m√°s probables que otras
- **Ejemplo**: Distribuci√≥n de ingresos (pocos muy ricos, muchos con ingresos medios/bajos)
- **En ML**: Datasets desbalanceados (fraude: 99% leg√≠timo, 1% fraude)
- Entrop√≠a menor ‚Üí m√°s predecible
- Requiere t√©cnicas especiales de balance

## 2.4 Valor Esperado

**Definici√≥n**: Promedio ponderado de todos los resultados posibles
```
E[X] = Œ£ (valor_i √ó probabilidad_i)
```

**Ejemplo 1: Inversi√≥n**
Invertir $1000 con posibles resultados:
- 30% probabilidad de ganar $500 ‚Üí valor = $1500
- 50% probabilidad de ganar $100 ‚Üí valor = $1100
- 20% probabilidad de perder $200 ‚Üí valor = $800

E[inversi√≥n] = (1500 √ó 0.3) + (1100 √ó 0.5) + (800 √ó 0.2) = $1160
Ganancia esperada = $1160 - $1000 = $160

**Ejemplo 2: Clasificador ML**
Resultados posibles:
- Correcto (ganancia = +10), P = 0.8
- Incorrecto (costo = -30), P = 0.2

E[decisi√≥n] = (10 √ó 0.8) + (-30 √ó 0.2) = 8 - 6 = +2 (beneficio neto positivo)

**Aplicaci√≥n en ML:**
- Decisiones bajo incertidumbre
- Optimizaci√≥n de funciones de costo
- Evaluaci√≥n de estrategias de negocio con modelos predictivos

## 2.5 Entrop√≠a de Shannon

**Definici√≥n**: Medida del desorden o incertidumbre en un conjunto de datos
```
H(X) = -Œ£ P(xi) √ó log‚ÇÇ(P(xi))
```

**Interpretaci√≥n:**
- H = 0: Certeza total (sin incertidumbre)
- H = log‚ÇÇ(n): M√°xima entrop√≠a para n opciones equiprobables
- H intermedia: Incertidumbre parcial

**Ejemplo 1: Lanzamiento de moneda**
Moneda justa:
- P(cara) = 0.5, P(cruz) = 0.5
- H = -(0.5√ólog‚ÇÇ(0.5) + 0.5√ólog‚ÇÇ(0.5)) = 1 bit
- M√°xima incertidumbre para 2 opciones

Moneda trucada:
- P(cara) = 0.9, P(cruz) = 0.1
- H = -(0.9√ólog‚ÇÇ(0.9) + 0.1√ólog‚ÇÇ(0.1)) ‚âà 0.47 bits
- M√°s predecible, menor incertidumbre

**Ejemplo 2: Clasificaci√≥n de emails**
Dataset balanceado:
- P(spam) = 0.5, P(no_spam) = 0.5
- H = 1 bit (m√°xima incertidumbre)

Dataset desbalanceado:
- P(spam) = 0.05, P(no_spam) = 0.95
- H ‚âà 0.29 bits (muy predecible: casi siempre no-spam)

**Aplicaci√≥n en ML:**
- **√Årboles de decisi√≥n**: Maximizar ganancia de informaci√≥n (reducir entrop√≠a)
- **Feature engineering**: Features con alta entrop√≠a ‚Üí m√°s informaci√≥n
- **Evaluaci√≥n de modelos**: Entrop√≠a cruzada (cross-entropy) como funci√≥n de p√©rdida
- **Compresi√≥n de datos**: Mayor entrop√≠a ‚Üí m√°s dif√≠cil comprimir

---

# PARTE 3: TIPOS DE APRENDIZAJE AUTOM√ÅTICO

## 3.1 Aprendizaje Supervisado

**Definici√≥n**: Aprendemos de ejemplos etiquetados (sabemos la respuesta correcta)

**Caracter√≠sticas:**
- Tenemos pares (entrada, salida esperada)
- El modelo aprende la relaci√≥n entrada‚Üísalida
- Objetivo: Predecir salidas para nuevas entradas

**Ejemplos reales:**

**1. Clasificaci√≥n de emails:**
```
Entrenamiento:
email1: "Compra ahora descuento..." ‚Üí spam
email2: "Reuni√≥n ma√±ana a las 10..." ‚Üí no-spam
email3: "Gana dinero r√°pido..." ‚Üí spam
...
Predicci√≥n:
email_nuevo: "Oferta exclusiva..." ‚Üí ??? (el modelo predice: spam)
```

**2. Reconocimiento de d√≠gitos escritos a mano:**
```
Entrenamiento:
imagen1: [pixels...] ‚Üí 7
imagen2: [pixels...] ‚Üí 3
imagen3: [pixels...] ‚Üí 7
...
Predicci√≥n:
imagen_nueva: [pixels...] ‚Üí ??? (el modelo predice: 7)
```

**3. Predicci√≥n de precio de casas:**
```
Entrenamiento:
casa1: (100m¬≤, 2 hab, centro) ‚Üí $200,000
casa2: (80m¬≤, 1 hab, periferia) ‚Üí $120,000
casa3: (150m¬≤, 3 hab, centro) ‚Üí $350,000
...
Predicci√≥n:
casa_nueva: (120m¬≤, 2 hab, centro) ‚Üí ??? (el modelo predice: $280,000)
```

### Algoritmos comunes:

**Regresi√≥n** (predecir valores continuos):
- **Regresi√≥n Lineal**: y = mx + b (ejemplo: predecir precio de casa)
- **Regresi√≥n Polin√≥mica**: relaciones no lineales
- **Random Forest Regressor**: combinaci√≥n de √°rboles
- Ejemplos de uso: Predecir ventas, temperatura, precios de acciones

**Clasificaci√≥n** (predecir categor√≠as discretas):
- **Regresi√≥n Log√≠stica**: clasificaci√≥n binaria (s√≠/no, spam/no-spam)
- **√Årboles de Decisi√≥n**: reglas if-then jer√°rquicas
- **Random Forest**: ensemble de √°rboles
- **Naive Bayes**: basado en probabilidades condicionales
- **Support Vector Machines (SVM)**: encuentra hiperplano √≥ptimo
- **K-Nearest Neighbors (KNN)**: clasifica por vecinos m√°s cercanos
- **Redes Neuronales**: modelos complejos inspirados en el cerebro
- Ejemplos de uso: Filtro spam, reconocimiento de im√°genes, diagn√≥stico m√©dico

## 3.2 Aprendizaje No Supervisado

**Definici√≥n**: Encontrar patrones en datos sin etiquetas

**Caracter√≠sticas:**
- Solo tenemos entradas, no salidas
- El modelo encuentra estructura oculta
- Objetivo: Descubrir agrupaciones o patrones

**Ejemplos reales:**

**1. Segmentaci√≥n de clientes (Clustering):**
```
Datos: [(edad, ingresos, compras_mes), ...]
       [(25, 30K, 5), (45, 80K, 15), (28, 35K, 6), ...]

Descubrimiento autom√°tico:
- Cluster 1: J√≥venes, ingresos medios, compras moderadas
- Cluster 2: Adultos, altos ingresos, muchas compras
- Cluster 3: Seniors, ingresos variables, pocas compras

Sin que le digamos qu√© grupos buscar!
```

**2. Detecci√≥n de anomal√≠as en transacciones:**
```
Datos: Miles de transacciones bancarias normales
Modelo aprende: Qu√© es "normal"
Resultado: Detecta transacciones sospechosas que se desv√≠an del patr√≥n
```

**3. Reducci√≥n de dimensionalidad:**
```
Datos originales: 1000 features por imagen
Despu√©s de PCA: 50 features principales que capturan 95% de la varianza
Beneficio: Procesamiento m√°s r√°pido, menos ruido, visualizaci√≥n posible
```

### T√©cnicas principales:

**Clustering (agrupaci√≥n):**
- **K-Means**: Agrupa datos en K clusters
- **DBSCAN**: Encuentra clusters de formas arbitrarias
- **Hierarchical Clustering**: Crea jerarqu√≠a de clusters
- Aplicaciones: Segmentaci√≥n de mercado, organizaci√≥n de documentos, compresi√≥n de im√°genes

**Reducci√≥n de Dimensionalidad:**
- **PCA (Principal Component Analysis)**: Encuentra direcciones de m√°xima varianza
- **t-SNE**: Visualizaci√≥n de datos de alta dimensi√≥n
- **Autoencoders**: Redes neuronales que aprenden representaciones compactas
- Aplicaciones: Visualizaci√≥n, preprocesamiento, compresi√≥n

**Detecci√≥n de Anomal√≠as:**
- **Isolation Forest**: A√≠sla observaciones an√≥malas
- **One-Class SVM**: Define regi√≥n de normalidad
- **Autoencoders**: Detecta datos que reconstruye mal
- Aplicaciones: Fraude, fallos en sistemas, ciber-seguridad

**Reglas de Asociaci√≥n:**
- **Apriori**: Encuentra patrones frecuentes
- **FP-Growth**: Versi√≥n optimizada
- Aplicaci√≥n cl√°sica: "Los clientes que compran X tambi√©n compran Y" (market basket analysis)

## 3.3 Aprendizaje por Refuerzo

**Definici√≥n**: Aprender mediante prueba y error con recompensas/castigos

**Caracter√≠sticas:**
- Agente interact√∫a con entorno
- Recibe recompensas (+) o penalizaciones (-)
- Objetivo: Maximizar recompensa total

**Ejemplos reales:**

**1. Robot aprendiendo a caminar:**
```
Estado: Posiciones de articulaciones, sensores de equilibrio
Acci√≥n: Mover motor X con fuerza Y
Resultado: Robot avanza 10cm ‚Üí Recompensa +10
         Robot se cae ‚Üí Recompensa -100
Aprendizaje: Ajusta acciones para maximizar distancia recorrida sin caerse
```

**2. AlphaGo jugando Go:**
```
Estado: Configuraci√≥n actual del tablero
Acci√≥n: Colocar ficha en posici√≥n (x,y)
Resultado: Ganar partida ‚Üí Recompensa +1
          Perder partida ‚Üí Recompensa -1
Aprendizaje: Aprende estrategias √≥ptimas despu√©s de millones de partidas
```

**3. Coche aut√≥nomo:**
```
Estado: Velocidad, posici√≥n en carril, veh√≠culos cercanos, se√±ales
Acci√≥n: Acelerar, frenar, girar
Resultado: Mantiene carril y velocidad ‚Üí Recompensa +1
          Salida de carril ‚Üí Recompensa -10
          Accidente ‚Üí Recompensa -1000
Aprendizaje: Pol√≠tica de conducci√≥n segura y eficiente
```

**4. Optimizaci√≥n de recursos en Data Center:**
```
Estado: Temperatura, carga de servidores, demanda
Acci√≥n: Ajustar enfriamiento, distribuir carga
Resultado: Ahorro de energ√≠a ‚Üí Recompensa positiva
          Sobrecalentamiento ‚Üí Recompensa negativa
Aprendizaje: Google logr√≥ reducir 40% del consumo energ√©tico en enfriamiento
```

### Componentes clave:

- **Agente**: El sistema que aprende y toma decisiones
- **Entorno**: El mundo con el que interact√∫a el agente
- **Estado (s)**: Situaci√≥n actual del entorno
- **Acci√≥n (a)**: Decisi√≥n que toma el agente
- **Recompensa (r)**: Feedback inmediato por la acci√≥n
- **Pol√≠tica (œÄ)**: Estrategia que mapea estados ‚Üí acciones
- **Funci√≥n de valor Q(s,a)**: Recompensa esperada a largo plazo

### Algoritmos principales:

- **Q-Learning**: Aprende valores Q de forma iterativa (tabular)
- **Deep Q-Network (DQN)**: Q-Learning con redes neuronales profundas
- **Policy Gradient**: Optimiza directamente la pol√≠tica
- **Actor-Critic**: Combina value-based y policy-based
- **A3C**: Asynchronous Advantage Actor-Critic
- **PPO**: Proximal Policy Optimization (usado en ChatGPT con RLHF)

## 3.4 ¬øCu√°ndo usar cada tipo de aprendizaje?

### Decision Tree para elegir tipo de ML:

```
¬øTienes datos etiquetados?
‚îÇ
‚îú‚îÄ S√ç ‚Üí ¬øQuieres predecir algo?
‚îÇ       ‚îÇ
‚îÇ       ‚îú‚îÄ S√ç ‚Üí APRENDIZAJE SUPERVISADO
‚îÇ       ‚îÇ       ‚îú‚îÄ Salida continua (precio, temperatura) ‚Üí REGRESI√ìN
‚îÇ       ‚îÇ       ‚îî‚îÄ Salida categ√≥rica (spam/no-spam) ‚Üí CLASIFICACI√ìN
‚îÇ       ‚îÇ
‚îÇ       ‚îî‚îÄ NO ‚Üí ¬øSolo quieres encontrar estructura?
‚îÇ               ‚îî‚îÄ APRENDIZAJE NO SUPERVISADO
‚îÇ
‚îî‚îÄ NO ‚Üí ¬øPuedes definir recompensas/castigos?
        ‚îÇ
        ‚îú‚îÄ S√ç ‚Üí ¬øEl sistema interact√∫a con un entorno?
        ‚îÇ       ‚îî‚îÄ S√ç ‚Üí APRENDIZAJE POR REFUERZO
        ‚îÇ
        ‚îî‚îÄ NO ‚Üí APRENDIZAJE NO SUPERVISADO
                ‚îú‚îÄ Agrupar datos similares ‚Üí CLUSTERING
                ‚îú‚îÄ Detectar datos raros ‚Üí DETECCI√ìN DE ANOMAL√çAS
                ‚îî‚îÄ Reducir complejidad ‚Üí REDUCCI√ìN DE DIMENSIONALIDAD
```

### Tabla comparativa:

| Caracter√≠stica | Supervisado | No Supervisado | Refuerzo |
|----------------|-------------|----------------|----------|
| **Datos etiquetados** | S√≠, necesarios | No necesarios | Opcional |
| **Objetivo** | Predecir salida | Encontrar estructura | Maximizar recompensa |
| **Feedback** | Etiquetas correctas | Ninguno | Recompensas |
| **Interacci√≥n** | Pasiva (datos fijos) | Pasiva | Activa (con entorno) |
| **Ejemplos** | Spam filter, precio casas | Segmentaci√≥n, clustering | Rob√≥tica, juegos |
| **Complejidad** | Media | Media-Baja | Alta |
| **Datos necesarios** | Muchos (con etiquetas) | Muchos (sin etiquetas) | Muchas iteraciones |

### Tendencias actuales:

- **Self-Supervised Learning**: H√≠brido entre supervisado y no supervisado (usado en GPT, BERT)
- **Semi-Supervised Learning**: Pocos datos etiquetados + muchos sin etiquetar
- **Transfer Learning**: Usar modelo pre-entrenado y adaptar a tu problema
- **Few-Shot Learning**: Aprender de muy pocos ejemplos
- **Meta-Learning**: "Aprender a aprender"

---

# PARTE 4: ALGORITMOS FUNDAMENTALES DE MACHINE LEARNING

## 4.1 Regresi√≥n Lineal

**Principio**: Encontrar la l√≠nea que mejor se ajusta a los datos

**Modelo matem√°tico:**
```
y = Œ≤‚ÇÄ + Œ≤‚ÇÅx‚ÇÅ + Œ≤‚ÇÇx‚ÇÇ + ... + Œ≤‚Çôx‚Çô + Œµ

Donde:
- y = variable objetivo (lo que queremos predecir)
- x‚ÇÅ, x‚ÇÇ, ..., x‚Çô = features (variables independientes)
- Œ≤‚ÇÄ = intercepto (bias)
- Œ≤‚ÇÅ, Œ≤‚ÇÇ, ..., Œ≤‚Çô = coeficientes (pesos)
- Œµ = error
```

**Funci√≥n de costo (MSE - Mean Squared Error):**
```
J(Œ≤) = (1/n) Œ£(y_real - y_pred)¬≤
```

**Ventajas:**
- Simple y muy interpretable
- R√°pido de entrenar
- Funciona bien con relaciones lineales
- Baseline excelente para comparar

**Desventajas:**
- Asume linealidad (puede no capturar relaciones complejas)
- Sensible a outliers
- Puede sufrir de multicolinealidad

**Aplicaciones:**
- Predicci√≥n de precios (casas, acciones)
- Estimaci√≥n de ventas
- An√°lisis de tendencias
- Econometr√≠a

## 4.2 Cadenas de Markov

**Principio**: "El siguiente estado depende solo del estado actual" (Propiedad de Markov)

**Definici√≥n formal:**
```
P(X_{t+1} = s_{j} | X_t = s_i, X_{t-1} = s_{k}, ...) = P(X_{t+1} = s_j | X_t = s_i)
```

El futuro es independiente del pasado dado el presente.

**Matriz de transici√≥n P:**
```
        Estado_1  Estado_2  Estado_3
Estado_1   0.7      0.2       0.1
Estado_2   0.3      0.5       0.2
Estado_3   0.4      0.1       0.5
```

**Ejemplo: Predicci√≥n del clima**
```
Estados: {Soleado, Nublado, Lluvioso}

Matriz de transici√≥n:
              Soleado  Nublado  Lluvioso
Soleado        0.8      0.15     0.05
Nublado        0.3      0.4      0.3
Lluvioso       0.2      0.3      0.5

Interpretaci√≥n:
- Si hoy est√° Soleado, ma√±ana hay 80% de probabilidad de sol
- Si hoy est√° Lluvioso, ma√±ana hay 50% de probabilidad de lluvia
```

**Predicci√≥n:**
```
Estado actual: Nublado
Probabilidades para ma√±ana:
  P(Soleado) = 0.3
  P(Nublado) = 0.4
  P(Lluvioso) = 0.3

Predicci√≥n: Nublado (m√°xima probabilidad)
```

**Aplicaciones en ML:**
- Modelado de secuencias (texto, ADN, comportamiento de usuarios)
- Sistemas de recomendaci√≥n
- Procesamiento de lenguaje natural (n-gramas)
- Reconocimiento de voz
- PageRank de Google (variante: Markov con random walk)

## 4.3 N-gramas y Modelos de Lenguaje

**Principio**: Predecir el siguiente elemento bas√°ndose en N elementos anteriores

**N-grama**: Secuencia de N elementos consecutivos (palabras, caracteres, etc.)

### Tipos de N-gramas:

**Unigrama (N=1)**: Elementos individuales
```
Texto: "El gato come pescado"
Unigramas: ["El", "gato", "come", "pescado"]
P("gato") = frecuencia("gato") / total_palabras
```

**Bigrama (N=2)**: Pares de elementos consecutivos
```
Texto: "El gato come pescado. El perro come carne."
Bigramas: [("El", "gato"), ("gato", "come"), ("come", "pescado"),
           ("El", "perro"), ("perro", "come"), ("come", "carne")]

Tabla de probabilidades condicionales:
P("gato" | "El") = 1/2 = 0.5
P("perro" | "El") = 1/2 = 0.5
P("pescado" | "come") = 1/2 = 0.5
P("carne" | "come") = 1/2 = 0.5
```

**Trigrama (N=3)**: Tripletes
```
Trigramas: [("El", "gato", "come"), ("gato", "come", "pescado"), ...]
P("come" | "El", "gato") = frecuencia("El gato come") / frecuencia("El gato")
```

### Ejemplo pr√°ctico: Autocompletado

```
Modelo entrenado con millones de textos:
Usuario escribe: "Buenos"
  ‚Üí Predicciones bigramas: ["d√≠as" (60%), "noches" (20%), "Aires" (15%), ...]

Usuario escribe: "Buenos d√≠as"
  ‚Üí Predicciones trigramas: ["." (40%), "se√±or" (20%), "a" (15%), ...]
```

### Aplicaciones:

**1. Procesamiento de Lenguaje Natural:**
- Correcci√≥n ortogr√°fica y gramatical
- Autocompletado de texto (teclados, buscadores)
- Traducci√≥n autom√°tica
- Generaci√≥n de texto

**2. Bioinform√°tica:**
- An√°lisis de secuencias de ADN/prote√≠nas
- Predicci√≥n de estructura gen√©tica

**3. Sistemas de recomendaci√≥n:**
- "Los usuarios que vieron A y B, vieron C"
- Secuencias de compras

**4. Detecci√≥n de anomal√≠as:**
- Identificar patrones inusuales en logs de sistema
- Seguridad: detectar comportamientos an√≥malos

### Problema del N-grama: Sparsity

A mayor N, m√°s precisi√≥n PERO:
- Necesitas MUCHO m√°s datos
- Muchas combinaciones nunca vistas en entrenamiento
- M√°s memoria requerida

**Soluci√≥n moderna**: Redes neuronales (LSTM, Transformers) que capturan contexto sin enumerar todas las combinaciones

## 4.4 K-Nearest Neighbors (KNN)

**Principio**: "Dime con qui√©n andas y te dir√© qui√©n eres" - Los puntos similares est√°n cerca

**Algoritmo:**
1. Calcular distancia entre nuevo punto y todos los puntos de entrenamiento
2. Seleccionar los K vecinos m√°s cercanos
3. Para clasificaci√≥n: votar por la clase mayoritaria
4. Para regresi√≥n: promediar los valores

**Ejemplo: Clasificar una flor**
```
Nuevaflor: longitud_p√©talo=5.1, ancho_p√©talo=3.2

K=3 vecinos m√°s cercanos:
  1. Iris-setosa (distancia=0.8)
  2. Iris-setosa (distancia=1.1)
  3. Iris-versicolor (distancia=1.5)

Predicci√≥n: Iris-setosa (2 votos vs 1)
```

**Distancias comunes:**

**Euclidiana** (m√°s com√∫n):
```
d = ‚àö[(x‚ÇÅ-x‚ÇÇ)¬≤ + (y‚ÇÅ-y‚ÇÇ)¬≤]
```

**Manhattan**:
```
d = |x‚ÇÅ-x‚ÇÇ| + |y‚ÇÅ-y‚ÇÇ|
```

**Minkowski** (generalizaci√≥n):
```
d = (|x‚ÇÅ-x‚ÇÇ|·µñ + |y‚ÇÅ-y‚ÇÇ|·µñ)^(1/p)
donde p=1 ‚Üí Manhattan, p=2 ‚Üí Euclidiana
```

**Elecci√≥n de K:**
- K peque√±o (1-3): Sensible a ruido, fronteras complejas
- K grande (>10): M√°s robusto pero fronteras muy suaves
- Regla emp√≠rica: K = ‚àön donde n = n√∫mero de muestras
- Usar K impar para evitar empates en clasificaci√≥n binaria

**Ventajas:**
- Simple de entender e implementar
- No requiere entrenamiento (lazy learning)
- Funciona bien con fronteras no lineales
- √ötil para datasets peque√±os

**Desventajas:**
- Lento en predicci√≥n (debe calcular todas las distancias)
- Sensible a la escala de features (necesita normalizaci√≥n)
- Maldici√≥n de la dimensionalidad (alta dimensi√≥n ‚Üí todo est√° "lejos")
- Requiere mucha memoria (guarda todos los datos)

**Aplicaciones:**
- Sistemas de recomendaci√≥n ("usuarios similares a ti")
- Reconocimiento de patrones
- Clasificaci√≥n de im√°genes
- Detecci√≥n de anomal√≠as

## 4.5 Ensemble Methods (M√©todos de Conjunto)

**Principio**: "Muchas cabezas piensan mejor que una"

Combinar m√∫ltiples modelos para obtener mejor rendimiento que cualquier modelo individual.

### Tipos de Ensemble:

**1. Voting (Votaci√≥n)**

**Hard Voting** (mayor√≠a simple):
```
Clasificador 1: Clase A
Clasificador 2: Clase A
Clasificador 3: Clase B
Clasificador 4: Clase A

Predicci√≥n final: Clase A (3 votos vs 1)
```

**Soft Voting** (promedio de probabilidades):
```
Clasificador 1: P(A)=0.6, P(B)=0.4
Clasificador 2: P(A)=0.8, P(B)=0.2
Clasificador 3: P(A)=0.5, P(B)=0.5

Promedio: P(A)=0.63, P(B)=0.37
Predicci√≥n final: Clase A
```

**2. Bagging (Bootstrap Aggregating)**

Ejemplo: **Random Forest**
```
Dataset original: 1000 muestras

1. Crear N subsets con reemplazo (bootstrap)
   Subset1: muestra aleatoria de 1000 (con repeticiones)
   Subset2: muestra aleatoria de 1000
   ...
   Subset100: muestra aleatoria de 1000

2. Entrenar un √°rbol de decisi√≥n en cada subset

3. Predicci√≥n final: votar (clasificaci√≥n) o promediar (regresi√≥n)
```

**Ventajas:**
- Reduce varianza (overfitting)
- Funciona bien con modelos inestables (√°rboles)
- Paralelizable

**3. Boosting (Impulso)**

Modelos secuenciales donde cada uno corrige errores del anterior.

**AdaBoost** (Adaptive Boosting):
```
1. Entrenar modelo1 con datos
2. Identificar muestras mal clasificadas
3. Aumentar peso de muestras dif√≠ciles
4. Entrenar modelo2 enfoc√°ndose en errores de modelo1
5. Repetir N veces
6. Predicci√≥n final: voto ponderado de todos los modelos
```

**Gradient Boosting** (m√°s popular: XGBoost, LightGBM, CatBoost):
```
1. Modelo inicial: predicci√≥n simple (media)
2. Calcular residuos (errores)
3. Entrenar modelo para predecir residuos
4. Actualizar predicci√≥n: predicci√≥n_anterior + learning_rate √ó modelo_residuos
5. Repetir hasta convergencia
```

**Ventajas:**
- Reduce bias (underfitting)
- Muy potente en competiciones (Kaggle)
- Captura patrones complejos

**Desventajas:**
- M√°s lento de entrenar (secuencial)
- Puede hacer overfitting si no se regula

**4. Stacking (Apilamiento)**

```
Nivel 1 (Base Models):
  - Modelo A: KNN
  - Modelo B: SVM
  - Modelo C: √Årbol de Decisi√≥n

Nivel 2 (Meta-Model):
  Entrada: predicciones de A, B, C
  Modelo: Regresi√≥n Log√≠stica
  Salida: Predicci√≥n final
```

### Ejemplo pr√°ctico:

**Problema**: Predecir si un email es spam

```
Random Forest (100 √°rboles): Accuracy = 92%
Gradient Boosting: Accuracy = 93%
SVM: Accuracy = 91%

Ensemble (Voting): Accuracy = 95%
```

**¬øPor qu√© funciona?**
- Modelos diferentes cometen errores diferentes
- Al combinarlos, los errores se cancelan
- La "sabidur√≠a de las masas"

### Cu√°ndo usar cada tipo:

- **Bagging**: Datos con mucho ruido, reducir varianza
- **Boosting**: Mejorar modelos d√©biles, capturar patrones complejos
- **Stacking**: Maximizar rendimiento (competiciones)

---

# PARTE 5: M√âTRICAS Y EVALUACI√ìN DE MODELOS

## 5.1 M√©tricas para Clasificaci√≥n

### Accuracy (Exactitud)
```
Accuracy = (TP + TN) / (TP + TN + FP + FN)
         = Predicciones correctas / Total predicciones
```

**Ejemplo: Detector de spam**
```
De 100 emails:
- 90 correctamente clasificados
- 10 incorrectamente clasificados

Accuracy = 90/100 = 90%
```

**Limitaci√≥n**: No funciona bien con clases desbalanceadas

**Ejemplo del problema:**
```
Dataset: 95% clase A, 5% clase B
Modelo que siempre predice A: Accuracy = 95% (pero in√∫til para clase B!)
```

### Matriz de Confusi√≥n

La tabla fundamental para entender errores:

```
                    Predicho
                 Positivo  Negativo
Real  Positivo      TP        FN
      Negativo      FP        TN

TP = True Positives (Verdaderos Positivos)
TN = True Negatives (Verdaderos Negativos)
FP = False Positives (Falsos Positivos) - Error Tipo I
FN = False Negatives (Falsos Negativos) - Error Tipo II
```

**Ejemplo: Test m√©dico para enfermedad**
```
                  Predicho
               Enfermo  Sano
Real Enfermo    90(TP)  10(FN)    ‚Üê FN: Falso negativo (¬°peligroso!)
     Sano        20(FP) 880(TN)   ‚Üê FP: Falso positivo (alarma falsa)
```

### Precision (Precisi√≥n)
```
Precision = TP / (TP + FP)
```
"De todo lo que predijimos como positivo, ¬øcu√°nto era realmente positivo?"

**Ejemplo:**
```
Detector de spam predice 100 emails como spam
De esos 100, 85 son realmente spam

Precision = 85/100 = 85%
```

**Cu√°ndo es cr√≠tico**: Cuando FP son costosos (ej: marcar email importante como spam)

### Recall / Sensitivity (Sensibilidad / Exhaustividad)
```
Recall = TP / (TP + FN)
```
"De todos los positivos reales, ¬øcu√°ntos detectamos?"

**Ejemplo:**
```
Hay 90 emails de spam reales
El detector encontr√≥ 85 de ellos

Recall = 85/90 = 94.4%
```

**Cu√°ndo es cr√≠tico**: Cuando FN son costosos (ej: no detectar fraude, no detectar c√°ncer)

### F1-Score
```
F1 = 2 √ó (Precision √ó Recall) / (Precision + Recall)
```
Media arm√≥nica de Precision y Recall. Balance entre ambos.

**Ejemplo:**
```
Precision = 85%
Recall = 94.4%

F1 = 2 √ó (0.85 √ó 0.944) / (0.85 + 0.944) = 89.3%
```

### Specificity (Especificidad)
```
Specificity = TN / (TN + FP)
```
"De todos los negativos reales, ¬øcu√°ntos identificamos correctamente?"

### Trade-offs importantes:

**Precision vs Recall:**
```
Threshold alto ‚Üí Alta Precision, Bajo Recall
  (Solo predecimos positivo cuando muy seguros)

Threshold bajo ‚Üí Baja Precision, Alto Recall
  (Predecimos positivo con cualquier sospecha)
```

**Ejemplo pr√°ctico - Filtro de spam:**
```
Configuraci√≥n "Agresiva":
  Alto Recall (detecta 99% de spam)
  Baja Precision (muchos emails leg√≠timos marcados como spam)

Configuraci√≥n "Conservadora":
  Alta Precision (lo que marca es spam casi seguro)
  Bajo Recall (deja pasar algo de spam)
```

## 5.2 M√©tricas para Regresi√≥n

Cuando predecimos valores continuos (precio, temperatura, etc.):

### MSE (Mean Squared Error)
```
MSE = (1/n) Œ£(y_real - y_pred)¬≤
```
- Penaliza fuertemente errores grandes
- En unidades al cuadrado (dif√≠cil interpretar)
- Sensible a outliers

### RMSE (Root Mean Squared Error)
```
RMSE = ‚àöMSE = ‚àö[(1/n) Œ£(y_real - y_pred)¬≤]
```
- Mismas unidades que la variable objetivo
- M√°s interpretable que MSE
- Ejemplo: RMSE = $10,000 en predicci√≥n de precios de casas

### MAE (Mean Absolute Error)
```
MAE = (1/n) Œ£|y_real - y_pred|
```
- Promedio de errores absolutos
- Menos sensible a outliers que MSE
- F√°cil de interpretar

### R¬≤ (R-squared / Coeficiente de Determinaci√≥n)
```
R¬≤ = 1 - (SS_residual / SS_total)
donde:
SS_residual = Œ£(y_real - y_pred)¬≤
SS_total = Œ£(y_real - y_mean)¬≤
```

**Interpretaci√≥n:**
- R¬≤ = 1: Predicci√≥n perfecta
- R¬≤ = 0: Modelo tan bueno como predecir la media
- R¬≤ < 0: Peor que predecir la media

**Ejemplo:**
```
R¬≤ = 0.85 ‚Üí El modelo explica el 85% de la varianza en los datos
```

### MAPE (Mean Absolute Percentage Error)
```
MAPE = (100/n) Œ£|((y_real - y_pred)/y_real)|
```
- Error en porcentaje
- √ötil para comparar modelos en diferentes escalas
- Problema: indefinido cuando y_real = 0

## 5.3 Validaci√≥n del Modelo

### Divisi√≥n de Datos (Train/Validation/Test Split)

```
Dataset completo: 10,000 muestras

‚îú‚îÄ‚îÄ Entrenamiento (Train): 7,000 (70%)
‚îÇ   ‚îî‚îÄ‚îÄ Para entrenar el modelo
‚îÇ
‚îú‚îÄ‚îÄ Validaci√≥n (Validation): 1,500 (15%)
‚îÇ   ‚îî‚îÄ‚îÄ Para ajustar hiperpar√°metros y prevenir overfitting
‚îÇ
‚îî‚îÄ‚îÄ Test: 1,500 (15%)
    ‚îî‚îÄ‚îÄ Para evaluaci√≥n final (¬°NUNCA usar para entrenar!)
```

**Regla de oro**: El conjunto de test NUNCA debe verse durante desarrollo

### K-Fold Cross-Validation

```
Dataset dividido en K=5 partes (folds):

Iteraci√≥n 1: [Test][Train][Train][Train][Train]
Iteraci√≥n 2: [Train][Test][Train][Train][Train]
Iteraci√≥n 3: [Train][Train][Test][Train][Train]
Iteraci√≥n 4: [Train][Train][Train][Test][Train]
Iteraci√≥n 5: [Train][Train][Train][Train][Test]

M√©trica final: Promedio de las 5 iteraciones
```

**Ventajas:**
- Usa todos los datos para entrenar y validar
- Estimaci√≥n m√°s robusta del rendimiento
- Reduce varianza de la evaluaci√≥n

**Cu√°ndo usar:**
- Datasets peque√±os (< 10,000 muestras)
- Cuando quieres m√°xima robustez
- No en deep learning (muy costoso computacionalmente)

### Overfitting vs Underfitting

```
Error de entrenamiento vs Error de validaci√≥n:

UNDERFITTING:
Train error: ALTO
Val error: ALTO
‚Üí Modelo muy simple, no captura patrones

BALANCE √ìPTIMO (¬°meta!):
Train error: BAJO
Val error: BAJO
‚Üí Generaliza bien

OVERFITTING:
Train error: MUY BAJO
Val error: ALTO
‚Üí Memoriza datos de entrenamiento, no generaliza
```

**Se√±ales de Overfitting:**
- Gran diferencia entre error de train y validation
- Accuracy 100% en train, 60% en validation
- Modelo funciona perfecto en desarrollo, mal en producci√≥n

**Se√±ales de Underfitting:**
- Error alto en train y validation
- Modelo demasiado simple para la complejidad del problema

**C√≥mo combatir Overfitting:**
1. M√°s datos de entrenamiento
2. Regularizaci√≥n (L1, L2, Dropout)
3. Reducir complejidad del modelo
4. Early stopping
5. Data augmentation
6. Cross-validation

**C√≥mo combatir Underfitting:**
1. Modelo m√°s complejo
2. M√°s features relevantes
3. Reducir regularizaci√≥n
4. M√°s tiempo de entrenamiento

---

# PARTE 6: CONCEPTOS AVANZADOS

## 7.2 Teor√≠a de la Informaci√≥n

### Informaci√≥n Mutua
¬øCu√°nta informaci√≥n sobre B nos da conocer A?
```
I(X;Y) = H(X) - H(X|Y)
```

Si I(Jugada_actual; Jugada_anterior) > 0 ‚Üí ¬°Hay dependencia!

### Compresi√≥n y Predicci√≥n
"La mejor compresi√≥n es la mejor predicci√≥n"
- Si podemos comprimir el historial ‚Üí hay patrones
- Historial aleatorio ‚Üí incompresible

## 7.3 Aprendizaje Online vs Batch

### Batch Learning
- Entrena con todos los datos de una vez
- No se adapta durante el juego

### Online Learning
- Actualiza con cada nueva jugada
- Se adapta en tiempo real
- Nuestro proyecto usa esto

### Tasa de Aprendizaje
```
nuevo_peso = peso_anterior + Œ± √ó (realidad - predicci√≥n)
```
- Œ± alta: Aprende r√°pido, olvida r√°pido
- Œ± baja: Aprende lento, memoria larga

---

# PARTE 8: ARQUITECTURA DE UN SISTEMA DE IA

## 8.1 Pipeline de Machine Learning

```
1. RECOLECCI√ìN DE DATOS
   ‚Üì
2. PREPROCESAMIENTO
   - Limpieza
   - Normalizaci√≥n
   - Feature Engineering
   ‚Üì
3. ENTRENAMIENTO
   - Selecci√≥n de algoritmo
   - Ajuste de hiperpar√°metros
   ‚Üì
4. VALIDACI√ìN
   - M√©tricas
   - Cross-validation
   ‚Üì
5. PREDICCI√ìN
   ‚Üì
6. EVALUACI√ìN Y MEJORA
   ‚Üì
(Ciclo continuo)
```

## 8.2 Feature Engineering

**Features b√°sicas**:
- √öltima jugada
- Frecuencias hist√≥ricas
- Racha actual

**Features avanzadas**:
- Entrop√≠a √∫ltimas 10 jugadas
- Tiempo desde √∫ltimo cambio
- Patr√≥n dominante actual
- Estado emocional inferido

## 8.3 Ensemble Methods

Combinar m√∫ltiples modelos para mejor resultado:

**Voting**:
```
Modelo1: Piedra
Modelo2: Piedra  ‚Üí Mayor√≠a: Piedra
Modelo3: Papel
```

**Stacking**:
```
Nivel 1: Modelos base hacen predicciones
Nivel 2: Meta-modelo decide bas√°ndose en predicciones nivel 1
```

**Boosting**:
Modelos secuenciales, cada uno corrige errores del anterior.

---

# PARTE 9: IMPLEMENTACI√ìN PR√ÅCTICA

## 9.1 Estructura de Datos

### Representaci√≥n del Estado
```python
estado = {
    'historial': ['piedra', 'papel', 'tijera', ...],
    'marcador': {'victorias': 10, 'derrotas': 8, 'empates': 5},
    'patrones_detectados': {('p','p'): 'tijera', ...},
    'tiempo_respuesta': [2.1, 1.8, 3.2, ...],
    'metadata': {'timestamp': ..., 'sesion': 1}
}
```

### Codificaci√≥n
```
Piedra = 0, Papel = 1, Tijera = 2
One-hot: Piedra = [1,0,0], Papel = [0,1,0], Tijera = [0,0,1]
```

## 9.2 Algoritmo Principal

```
INICIALIZAR modelos
MIENTRAS juego_activo:
    estado = OBTENER_ESTADO_ACTUAL()
    
    PARA CADA modelo EN modelos:
        predicciones[modelo] = modelo.predecir(estado)
    
    decision = COMBINAR_PREDICCIONES(predicciones)
    resultado = JUGAR(decision)
    
    ACTUALIZAR_MODELOS(resultado)
    ACTUALIZAR_PESOS(rendimiento)
```

## 9.3 Optimizaciones

### Cach√© de Patrones
Guardar patrones ya calculados para no recalcular.

### Ventana Adaptativa
Ajustar tama√±o de ventana seg√∫n entrop√≠a actual.

### Decay de Memoria
Dar menos peso a jugadas muy antiguas:
```
peso = e^(-Œª √ó antig√ºedad)
```

---

# PARTE 10: EVALUACI√ìN EXPERIMENTAL

## 10.1 Dise√±o de Experimentos

### Variables Independientes
- Tipo de algoritmo
- Tama√±o de ventana
- Longitud de patrones

### Variables Dependientes  
- Tasa de victoria
- Tiempo de convergencia
- Robustez ante cambios

### Variables de Control
- N√∫mero de jugadas
- Tipo de oponente
- Semilla aleatoria

## 10.2 Hip√≥tesis a Probar

1. **H1**: Los patrones de longitud 3 predicen mejor que longitud 2
2. **H2**: La ventana adaptativa supera a la ventana fija
3. **H3**: El ensemble supera a cualquier modelo individual
4. **H4**: La precisi√≥n mejora logar√≠tmicamente con los datos

## 10.3 An√°lisis Estad√≠stico

### Test de Significancia
¬øLa diferencia entre modelos es estad√≠sticamente significativa?
- t-test para comparar medias
- p-value < 0.05 ‚Üí Significativo

### Intervalos de Confianza
"Con 95% confianza, la tasa de victoria est√° entre 42% y 48%"

### An√°lisis de Varianza (ANOVA)
Comparar m√∫ltiples modelos simult√°neamente.

---

# EJERCICIOS TE√ìRICOS

## Ejercicio 1: Probabilidad
Un jugador tiene estas estad√≠sticas:
- Juega piedra 45% del tiempo
- Juega papel 35% del tiempo  
- Juega tijera 20% del tiempo

Calcula:
a) La probabilidad de que ganes si siempre juegas papel
b) Tu mejor estrategia fija
c) El valor esperado de tu mejor estrategia

## Ejercicio 2: Entrop√≠a
Calcula la entrop√≠a de estos jugadores:
a) [piedra, piedra, piedra, piedra, piedra]
b) [piedra, papel, tijera, piedra, papel]
c) ¬øCu√°l es m√°s predecible?

## Ejercicio 3: Patrones
Dado el historial: [P, P, T, P, P, T, P, P, ?]
a) ¬øQu√© predices para '?'?
b) ¬øQu√© patr√≥n identificas?
c) ¬øQu√© jugar√≠as t√∫?

## Ejercicio 4: Markov
Construye la matriz de transici√≥n para:
[piedra, papel, papel, tijera, piedra, papel, tijera, tijera, piedra]

## Ejercicio 5: Teor√≠a de Juegos
Demuestra por qu√© en PPT perfecto, la estrategia √≥ptima es 1/3 para cada opci√≥n.

---

# CONEXI√ìN CON EL PROYECTO

Ahora que entend√©is la teor√≠a, en vuestro proyecto vais a:

1. **Implementar** estos algoritmos en c√≥digo Python
2. **Experimentar** con diferentes estrategias
3. **Medir** el rendimiento con las m√©tricas aprendidas
4. **Optimizar** bas√°ndoos en los resultados
5. **Competir** para ver qui√©n tiene el mejor modelo

La teor√≠a os da las herramientas, ¬°la pr√°ctica os dar√° la experiencia!

---

# RECURSOS ADICIONALES

## Libros Recomendados
- "Pattern Recognition and Machine Learning" - Bishop (avanzado)
- "The Elements of Statistical Learning" - Hastie et al. (intermedio)
- "Machine Learning for Absolute Beginners" - Theobald (b√°sico)

## Papers Relevantes
- Shannon, C. (1948). "A Mathematical Theory of Communication"
- Nash, J. (1951). "Non-Cooperative Games"
- Sutton & Barto. "Reinforcement Learning: An Introduction"

## Cursos Online Gratuitos
- Andrew Ng's Machine Learning Course (Coursera)
- Fast.ai Practical Deep Learning
- Google's Machine Learning Crash Course

## Herramientas y Librer√≠as
- **scikit-learn**: ML cl√°sico en Python
- **pandas**: An√°lisis de datos
- **numpy**: Computaci√≥n num√©rica
- **matplotlib**: Visualizaci√≥n

---

# CONCLUSI√ìN

La IA y el Machine Learning no son magia, son **matem√°ticas aplicadas** + **datos** + **algoritmos inteligentes**.

En este proyecto de Piedra, Papel o Tijera, vais a experimentar con todos estos conceptos:
- **Probabilidad** para entender las jugadas
- **Estad√≠stica** para analizar patrones
- **Algoritmos** para hacer predicciones
- **Evaluaci√≥n** para medir el √©xito
- **Iteraci√≥n** para mejorar continuamente

Lo m√°s importante: La IA aprende de los datos, pero **vosotros** aprender√©is del proceso.

¬°Que gane el mejor algoritmo! üéÆü§ñ
